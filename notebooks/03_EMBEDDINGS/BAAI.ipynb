{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample text test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Your sample text goes here.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Je m'apelle François\"\n",
    "\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs2)\n",
    "    embeddings2 = outputs.last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5604743957519531\n"
     ]
    }
   ],
   "source": [
    "# Assuming embeddings and embeddings2 are tensors of shape (1, hidden_dim)\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(embeddings, embeddings2, dim=1)\n",
    "\n",
    "# Print the similarity score\n",
    "print(\"Cosine Similarity:\", cosine_similarity.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test love hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5622000098228455\n"
     ]
    }
   ],
   "source": [
    "text = \"I love you\"\n",
    "text2 = \"They hate me\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "inputs2 = tokenizer(text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs2)\n",
    "    embeddings2 = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Assuming embeddings and embeddings2 are tensors of shape (1, hidden_dim)\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(embeddings, embeddings2, dim=1)\n",
    "\n",
    "# Print the similarity score\n",
    "print(\"Cosine Similarity:\", cosine_similarity.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples to actually search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarities with 1.npy: [0.7147541046142578, 0.7099173069000244, 0.7333047389984131, 0.6066607236862183]\n",
      "Cosine Similarities with 10.npy: [0.7633360624313354, 0.8169689178466797, 0.8212881684303284, 0.6160691380500793]\n",
      "Cosine Similarities with 11.npy: [0.7434858083724976, 0.7165929079055786, 0.6686182022094727, 0.6310552954673767]\n",
      "Cosine Similarities with 2.npy: [0.724294126033783, 0.7494648098945618, 0.7736704349517822, 0.6235658526420593]\n",
      "Cosine Similarities with 3.npy: [0.6889639496803284, 0.7040612697601318, 0.7218436002731323, 0.63972008228302]\n",
      "Cosine Similarities with 4.npy: [0.7428139448165894, 0.7360765337944031, 0.7158006429672241, 0.610838770866394]\n",
      "Cosine Similarities with 5.npy: [0.7063431143760681, 0.7119358777999878, 0.7008657455444336, 0.6176100373268127]\n",
      "Cosine Similarities with 6.npy: [0.7488690614700317, 0.8009746670722961, 0.7647774815559387, 0.6152656674385071]\n",
      "Cosine Similarities with 7.npy: [0.7615599632263184, 0.7418962717056274, 0.7225896716117859, 0.6340814828872681]\n",
      "Cosine Similarities with 8.npy: [0.7777950763702393, 0.755207896232605, 0.7323532104492188, 0.621391773223877]\n",
      "Cosine Similarities with 9.npy: [0.7091802954673767, 0.7297577857971191, 0.7514746785163879, 0.6376848220825195]\n",
      "Cosine Similarities with summary.npy: [0.6516140699386597, 0.718264639377594, 0.750755786895752, 0.5619727373123169]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to vectorize texts\n",
    "def vectorize_texts(texts, tokenizer, model):\n",
    "    # Tokenize all texts at once\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Get embeddings without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Calculate mean embedding for each text\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Shape: (n_texts, hidden_dim)\n",
    "    return embeddings\n",
    "\n",
    "# List of texts to vectorize\n",
    "texts = [\"¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?\", \"Luis comenta que la automatización está reemplazando trabajos repetitivos.\", \"Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.\", \"Otra cosa\"]  # Add all texts here\n",
    "\n",
    "\n",
    "# Vectorize the texts\n",
    "text_embeddings = vectorize_texts(texts, tokenizer, model)\n",
    "\n",
    "# Directory containing .npy vector files\n",
    "vector_dir = '/mnt/c/Users/luisg/Desktop/STAR/STAR/examples/conversation_sample_2/vectors'\n",
    "\n",
    "# Calculate cosine similarity for each text against each .npy vector\n",
    "for npy_file in os.listdir(vector_dir):\n",
    "    if npy_file.endswith(\".npy\"):\n",
    "        # Load the vector from .npy file\n",
    "        npy_vector = torch.tensor(np.load(os.path.join(vector_dir, npy_file)))\n",
    "        \n",
    "        # Ensure npy_vector is 2D for compatibility\n",
    "        if npy_vector.dim() == 1:\n",
    "            npy_vector = npy_vector.unsqueeze(0)\n",
    "        \n",
    "        # Compute cosine similarity for each text embedding with the current npy vector\n",
    "        similarities = torch.nn.functional.cosine_similarity(text_embeddings, npy_vector, dim=1)\n",
    "        \n",
    "        # Print or store the results\n",
    "        print(f\"Cosine Similarities with {npy_file}: {similarities.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 Cosine Similarities with 1.npy:\n",
      "  1: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7333047389984131\n",
      "  2: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7147541046142578\n",
      "  3: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7099173069000244\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6066607236862183\n",
      "Top 4 Cosine Similarities with 10.npy:\n",
      "  1: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.8212881684303284\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.8169689178466797\n",
      "  3: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7633360624313354\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6160691380500793\n",
      "Top 4 Cosine Similarities with 11.npy:\n",
      "  1: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7434858083724976\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7165929079055786\n",
      "  3: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.6686182022094727\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6310552954673767\n",
      "Top 4 Cosine Similarities with 2.npy:\n",
      "  1: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7736704349517822\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7494648098945618\n",
      "  3: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.724294126033783\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6235658526420593\n",
      "Top 4 Cosine Similarities with 3.npy:\n",
      "  1: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7218436002731323\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7040612697601318\n",
      "  3: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.6889639496803284\n",
      "  4: Text 'Otra cosa' - Similarity: 0.63972008228302\n",
      "Top 4 Cosine Similarities with 4.npy:\n",
      "  1: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7428139448165894\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7360765337944031\n",
      "  3: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7158006429672241\n",
      "  4: Text 'Otra cosa' - Similarity: 0.610838770866394\n",
      "Top 4 Cosine Similarities with 5.npy:\n",
      "  1: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7119358777999878\n",
      "  2: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7063431143760681\n",
      "  3: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7008657455444336\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6176100373268127\n",
      "Top 4 Cosine Similarities with 6.npy:\n",
      "  1: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.8009746670722961\n",
      "  2: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7647774815559387\n",
      "  3: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7488690614700317\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6152656674385071\n",
      "Top 4 Cosine Similarities with 7.npy:\n",
      "  1: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7615599632263184\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7418962717056274\n",
      "  3: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7225896716117859\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6340814828872681\n",
      "Top 4 Cosine Similarities with 8.npy:\n",
      "  1: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7777950763702393\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.755207896232605\n",
      "  3: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7323532104492188\n",
      "  4: Text 'Otra cosa' - Similarity: 0.621391773223877\n",
      "Top 4 Cosine Similarities with 9.npy:\n",
      "  1: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.7514746785163879\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.7297577857971191\n",
      "  3: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.7091802954673767\n",
      "  4: Text 'Otra cosa' - Similarity: 0.6376848220825195\n",
      "Top 4 Cosine Similarities with summary.npy:\n",
      "  1: Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.750755786895752\n",
      "  2: Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.718264639377594\n",
      "  3: Text '¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?' - Similarity: 0.6516140699386597\n",
      "  4: Text 'Otra cosa' - Similarity: 0.5619727373123169\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity for each text against each .npy vector\n",
    "for npy_file in os.listdir(vector_dir):\n",
    "    if npy_file.endswith(\".npy\"):\n",
    "        # Load the vector from .npy file\n",
    "        npy_vector = torch.tensor(np.load(os.path.join(vector_dir, npy_file)))\n",
    "        \n",
    "        # Ensure npy_vector is 2D for compatibility\n",
    "        if npy_vector.dim() == 1:\n",
    "            npy_vector = npy_vector.unsqueeze(0)\n",
    "        \n",
    "        # Compute cosine similarity for each text embedding with the current npy vector\n",
    "        similarities = torch.nn.functional.cosine_similarity(text_embeddings, npy_vector, dim=1)\n",
    "        \n",
    "        # Get the number of similarities available (up to 10)\n",
    "        num_top_values = min(10, similarities.size(0))\n",
    "        \n",
    "        # Get top values and indices based on available size\n",
    "        top_values, top_indices = torch.topk(similarities, num_top_values)\n",
    "        \n",
    "        # Print or store the top results\n",
    "        print(f\"Top {num_top_values} Cosine Similarities with {npy_file}:\")\n",
    "        for i, (value, idx) in enumerate(zip(top_values.tolist(), top_indices.tolist())):\n",
    "            print(f\"  {i + 1}: Text '{texts[idx]}' - Similarity: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matches Across All .npy Files (≥ 0.8):\n",
      "File '10.npy', Text 'Luis menciona que la automatización afecta la motivación y competencia de los trabajadores.' - Similarity: 0.8212881684303284\n",
      "File '10.npy', Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.8169689178466797\n",
      "File '6.npy', Text 'Luis comenta que la automatización está reemplazando trabajos repetitivos.' - Similarity: 0.8009746670722961\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store all similarity results\n",
    "all_similarities = []\n",
    "\n",
    "# Threshold for similarity scores\n",
    "similarity_threshold = 0.8\n",
    "\n",
    "# Calculate cosine similarity for each text against each .npy vector\n",
    "for npy_file in os.listdir(vector_dir):\n",
    "    if npy_file.endswith(\".npy\"):\n",
    "        # Load the vector from .npy file\n",
    "        npy_vector = torch.tensor(np.load(os.path.join(vector_dir, npy_file)))\n",
    "        \n",
    "        # Ensure npy_vector is 2D for compatibility\n",
    "        if npy_vector.dim() == 1:\n",
    "            npy_vector = npy_vector.unsqueeze(0)\n",
    "        \n",
    "        # Compute cosine similarity for each text embedding with the current npy vector\n",
    "        similarities = torch.nn.functional.cosine_similarity(text_embeddings, npy_vector, dim=1)\n",
    "        \n",
    "        # Store each similarity result that meets the threshold, along with the associated file and text\n",
    "        for idx, similarity in enumerate(similarities):\n",
    "            if similarity.item() >= similarity_threshold:\n",
    "                all_similarities.append((similarity.item(), texts[idx], npy_file))\n",
    "\n",
    "# Sort results in descending order for readability\n",
    "all_similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "# Print matches that meet or exceed the threshold\n",
    "print(f\"Cosine Similarity Matches Across All .npy Files (≥ {similarity_threshold}):\")\n",
    "for similarity, text, npy_file in all_similarities:\n",
    "    print(f\"File '{npy_file}', Text '{text}' - Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files with similarity ≥ 0.8: {'10', '6'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a set to store unique filenames that meet the threshold\n",
    "matching_files = set()\n",
    "\n",
    "# Calculate cosine similarity for each text against each .npy vector\n",
    "for npy_file in os.listdir(vector_dir):\n",
    "    if npy_file.endswith(\".npy\"):\n",
    "        # Load the vector from .npy file\n",
    "        npy_vector = torch.tensor(np.load(os.path.join(vector_dir, npy_file)))\n",
    "        \n",
    "        # Ensure npy_vector is 2D for compatibility\n",
    "        if npy_vector.dim() == 1:\n",
    "            npy_vector = npy_vector.unsqueeze(0)\n",
    "        \n",
    "        # Compute cosine similarity for each text embedding with the current npy vector\n",
    "        similarities = torch.nn.functional.cosine_similarity(text_embeddings, npy_vector, dim=1)\n",
    "        \n",
    "        # Check if any similarity meets or exceeds the threshold\n",
    "        if any(similarity.item() >= similarity_threshold for similarity in similarities):\n",
    "            # Add the filename without the .npy extension to the set\n",
    "            matching_files.add(os.path.splitext(npy_file)[0])\n",
    "\n",
    "# Output the set of matching filenames\n",
    "print(f\"Files with similarity ≥ {similarity_threshold}:\", matching_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate grok response with these chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIAL MESSAGE WITH GROK ###\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/luisg/Desktop/STAR/STAR/scripts')\n",
    "\n",
    "# Now you can import grok as if it's in the same directory\n",
    "import grok\n",
    "\n",
    "# Example usage\n",
    "client = grok.initialize_grok_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LUIS (11:14.00 - 11:19.00):  Ya está, quería volver al tema de los cuatro grupos. Entonces tenemos los caramelitos,  que serían el grupo muy motivado y muy competente. Tenemos luego un grupo muy competente pero poco motivado  que a eso habría que ver cómo aumentar esa motivación, ¿vale? Y que eso ya se ha visto  que pues por ejemplo para el Sistem se ha aumentado con este incremento de las tecnologías  y viendo que las condiciones laborales son buenas.\\nLIDIA (11:38.27 - 11:43.36):  La condición es incremento de herramientas que me permiten adquirir esa motivación desde\\nLUIS (11:43.36 - 11:51.03):  otras fuentes. Yo creo que también el reemplazo o la automatización de tareas repetitivas también es un aliciente  porque al final por una carrera muy técnica y un conocimiento muy bueno que tú tengas,  todos los trabajos hay tareas repetitivas, que eso es un coñazo, a nadie le gustan.  Y eso es bueno para poder hacer luego las personas un trabajo inteligente y productivo  y no perder horas de tu jornada laboral copiando celdas en un Excel.\\nLIDIA (12:16.55 - 12:16.84):  Luego tenemos el tercer grupo, que son los muy motivados pero poco competentes.  Entonces como aumentarse esa competencia, mediante programas de formación a lo mejor,\\nLUIS (12:29.00 - 12:33.00):  o desarrollo la parte teórica, porque la práctica ya la tienen. Vale, y finalmente con el grupo de poco motivados y poco competentes, ¿qué hacemos?\\nLIDIA (12:33.00 - 12:35.00):  Pues estos a los cajeros.  A los cajeros y que les sustituyan.\\nLUIS (12:37.00 - 12:38.00):  Exacto.  A estos renta básica universal y que no molesten mucho.  Estos son paquita, claro.  Les quitamos el derecho a voto y ya está.  Claro.\\n', 'LUIS (7:38.80 - 7:44.00):  Sí. Ah, a la gente que reemplazan por máquinas.\\nLIDIA (7:44.00 - 7:44.80):  Por máquinas, exacto.  Pues hay otro estudio.  ¿Dilo?  Sí, es el estudio de McKinsey que dice eso.  Fue escrito en 2017 y decía que antes de la pandemia  se estimaba ya que entre 400 y 800 millones de empleos  iban a ser reemplazados por máquinas.  Esto ya ha pasado. Ya hay muchísimos empleos que ya a ser reemplazados por máquinas. Esto ya ha pasado. O sea, ya  hay muchísimos empleos que ya se han reemplazado.\\nLUIS (8:07.56 - 8:10.95):  Y va a haber más. Antes eran trabajos más mecánicos, cajero y supermercado y tal.\\nLIDIA (8:10.95 - 8:15.75):  Sí, que también dicen que las tareas repetitivas son altamente susceptibles a la automatización.\\nLUIS (8:15.75 - 8:19.68):  Pero ahora cada vez más empleos quizás no tan repetitivos se van a ir sustituyendo,  como puede ser un conductor de taxi o de camión, o como puede ser trabajos incluso de oficina.  Esto también crea desmotivación.  Vale.  Sí, pero entonces lo que decías era para esta gente a la que están sustituyendo, tanto  para la gente joven como la gente mayor, ¿no?  Que a lo mejor llevan toda su carrera laboral haciendo este trabajo.\\nLIDIA (8:38.72 - 8:39.72):  Pues sí, a lo mejor una solución sería...\\nLUIS (8:39.72 - 8:40.72):  Darles opciones, ¿no?  O tenemos la renta básica universal para que puedan tener acceso a estudiar otras cosas.  Eso es de otro estudio, pero bueno, es una de las soluciones.\\n']\n"
     ]
    }
   ],
   "source": [
    "# Initialize chunk set\n",
    "chunk_set = matching_files\n",
    "\n",
    "# Initialize a list to store the content of each chunk\n",
    "chunk_list = []\n",
    "\n",
    "# Set chunks directory\n",
    "chunk_directory = '/mnt/c/Users/luisg/Desktop/STAR/STAR/examples/conversation_sample_2/chunks'\n",
    "\n",
    "# Read each chunk file and store its content\n",
    "for chunk_id in chunk_set:\n",
    "    file_path = os.path.join(chunk_directory, f\"{chunk_id}.txt\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            chunk_content = file.read()\n",
    "            chunk_list.append(chunk_content)\n",
    "    except FileNotFoundError:\n",
    "        chunk_list.append(f\"Chunk file {chunk_id}.txt not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luis ve la automatización de puestos de trabajo como una oportunidad para aumentar la motivación y la productividad de los empleados. Considera que reemplazar tareas repetitivas con máquinas permite a las personas enfocarse en trabajos más inteligentes y productivos, lo cual es un aliciente para los empleados. Además, menciona que la automatización ha afectado y seguirá afectando a más empleos, no solo los repetitivos, sino también aquellos que requieren menos repetición como conductores o trabajos de oficina, lo que puede generar desmotivación. Como solución, sugiere opciones como la renta básica universal para que los afectados puedan estudiar y adquirir nuevas competencias.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"¿Cuál es la opinión de Luis con respecto a la automatización de los puestos?\"\n",
    "\n",
    "grok_RAG_response = grok.respond_RAG_question(client, user_question, chunk_list)\n",
    "\n",
    "print(grok_RAG_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
